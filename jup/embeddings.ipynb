{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport warnings, gc\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Embedding, MaxPooling1D, Concatenate\nfrom keras.layers import SpatialDropout1D, Reshape, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Input\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_emb_size(nunique):\n    return int(min(50, np.ceil((nunique+1)/ 2) ))\n\ndef do_le(df, cols, single_emb=True):\n    for c in cols:\n        df[c] = df[c].astype('category')\n        df[c]= LabelEncoder().fit_transform(df[c])\n    if single_emb:\n        nuniques = [df[c].nunique() for c in cols]\n        offset = np.cumsum([0] + nuniques[:-1])\n        for i,c in enumerate(cols):\n            df[c] = df[c] + offset[i]\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_embs(emb_weights_pd):\n    m = emb_weights_pd.iloc[:,1:].as_matrix()\n    labels = emb_weights_pd.iloc[:,0:1].as_matrix()\n    fig = plt.figure(figsize=(20,10))\n    ax = Axes3D(fig)\n\n    for i in range(len(labels)):\n        ax.scatter(m[i,0],m[i,1],m[i,2], color='b')\n        ax.text(m[i,0],m[i,1],m[i,2],'%s'%(str(labels[i][0])), size=20, zorder=1, color='k')\n\n    ax.set_xlabel('Embedding 1')  \n    ax.set_ylabel('Embedding 2')  \n    ax.set_zlabel('Embedding 3')  \n    plt.show()\n    \ndef plot_history(histort):\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train','val'], loc='upper left')\n    plt.show()\n\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train','val'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/cat-in-the-dat/'\ndtr = pd.read_csv(path + \"train.csv\")\ndts = pd.read_csv(path + \"test.csv\")\nd = pd.concat([dtr, dts], sort=False)\ntrain_set = dtr.shape[0]\ndel(dtr, dts)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feats = [c for c in d.columns if c not in ['id','target']]\nd = do_le(d, cat_feats, single_emb=False)\ntrain = d[:train_set]\ntest = d[train_set:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['id','target'],1).as_matrix()\ny = train.target\nX_test = test.drop(['id','target'],1).as_matrix()\ntest = test[['id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X2 = np.concatenate([np.reshape(c, (-1,1) ) for c in X], axis=1)\nX_test2 = np.concatenate([np.reshape(c, (-1,1) ) for c in X_test], axis=1)\nnp.shape(X2),np.shape(X_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_emb(df, cols):\n        max_feats = df.nunique().sum()\n        emb_size = get_emb_size(max_feats)\n        max_len = df.shape[1]\n\n        model = Sequential()\n        model.add(Embedding(max_feats, emb_size, input_length=max_len, name=\"embedding\"))\n\n        model.add(Flatten())\n        model.add(Dropout(0.2))\n\n        model.add(Dense(2**6, activation='relu'))\n        model.add(Dropout(0.2))\n\n        model.add(Dense(2**6, activation='relu'))\n        model.add(Dropout(0.2))\n\n        model.add(Dense(1, activation='sigmoid'))\n\n        return model\n\ndef create_model_N_emb(df):\n        inps = []\n        outs = []\n        for c in df:\n            nunique = np.max(c)\n            emb_size = get_emb_size(nunique)\n            inp = Input(shape=(1,))\n            out = Embedding(nunique+1, emb_size, input_length=1)(inp)\n            out = SpatialDropout1D(0.3)(out)\n            inps.append(inp)\n            outs.append(out)\n\n        x = Concatenate()(outs)\n        x = Flatten()(x)\n        x = BatchNormalization()(x)\n\n        x = Dense(2**8, activation=\"relu\")(x)\n        x = Dropout(0.3)(x)\n        x = BatchNormalization()(x)\n\n        x = Dense(2**8, activation=\"relu\")(x)\n        x = Dropout(0.3)(x)\n        x = BatchNormalization()(x)\n        \n        y = Dense(1, activation='sigmoid')(x)\n        \n        model = Model(inputs=inps, outputs=y)\n        return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NSPLITS = 20\nSEED = 5555\nBATCH_SIZE = 1024\nEPOCHS = 10\n\noof = np.zeros((X.shape[0]))\ntest_preds = np.zeros(X_test.shape[0])\nskf = StratifiedKFold(n_splits=NSPLITS, random_state=SEED, shuffle=True)\n\nfor i, (tr, val) in enumerate(skf.split(X,y)):\n    X_tr = [c[tr] for c in X2]\n    X_val = [c[val] for c in X2]\n#     X_tr, X_val = X[tr,:], X[val,:]\n    y_tr, y_val = y[tr], y[val]\n    \n#     model = create_model_emb(d[cat_feats], cat_feats)\n    model = create_model_N_emb(X2)\n    \n    model.compile(loss='binary_crossentropy',\n                     optimizer='adam',\n                     metrics=['accuracy'])\n    \n    es = EarlyStopping(monitor='val_auc',\n                      min_delta=0.001,\n                      patience=2,\n                      verbose=1,\n                      mode='max',\n                      baseline=None,\n                      restore_best_weights=True)\n    \n    rlr = ReduceLROnPlateau(monitor='val_auc',\n                           factor=0.5,\n                           patience=3,\n                           min_lr=1e-6,\n                           mode='max',\n                           verbose=1)\n    \n    model.fit(X_tr, y_tr,\n              validation_data = (X_val, y_val),\n              verbose=1,\n              callbacks = [es, rlr],\n              batch_size=BATCH_SIZE,\n              epochs=EPOCHS,\n              shuffle=True)\n    \n    oof_pred = model.predict(X_val)\n    test_pred = model.predict(X_test)\n    \n    oof[val] = oof_pred.ravel()\n    test_preds += test_pred.ravel()\n    \n    print('-'*40)\n    print('Fold {}:\\t {:.5f}'.format(i, roc_auc_score(y_val, oof_pred)))\n    print('-'*40)\n    K.clear_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Overall AUC={}\".format(roc_auc_score(y, oof)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overall AUC=0.7956392905855455 many emb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred /= NSPLITS\ntest['pred'] = pred\nsub['target'] = pd.merge(sub, test, on='id')['pred']\nsub.to_csv('nn.csv', index=False)\nsub.tail()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}