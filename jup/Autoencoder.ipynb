{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport category_encoders\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DoubleValidationEncoderNumerical:\n    def __init__(self, cols, encoder, folds):\n        self.cols = cols\n        self.encoder = encoder\n        self.encoders_dict = {}\n        self.folds = folds\n\n    def fit_transform(self, X: pd.DataFrame, y: np.array) -> pd.DataFrame:\n        X = X.reset_index(drop=True)\n        y = y.reset_index(drop=True)\n        for n_fold, (train_idx, val_idx) in enumerate(self.folds.split(X, y)):\n            X_train, X_val = X.loc[train_idx].reset_index(drop=True), X.loc[val_idx].reset_index(drop=True)\n            y_train, y_val = y[train_idx], y[val_idx]\n            _ = self.encoder.fit_transform(X_train[self.cols], y_train)\n            \n            val_t = self.encoder.transform(X_val)\n            val_t = val_t.fillna(np.mean(y_train))\n            if n_fold == 0:\n                cols_representation = np.zeros((X.shape[0], val_t.shape[1]))\n            \n            self.encoders_dict[n_fold] = self.encoder\n            cols_representation[val_idx, :] += val_t.values\n        cols_representation = pd.DataFrame(cols_representation, columns=X.columns)\n        return cols_representation\n\n    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n        X = X.reset_index(drop=True)\n        cols_representation = None\n        for encoder in self.encoders_dict.values():\n            test_tr = encoder.transform(X)\n\n            if cols_representation is None:\n                cols_representation = np.zeros(test_tr.shape)\n            cols_representation = cols_representation + test_tr / self.folds.n_splits\n        cols_representation = pd.DataFrame(cols_representation, columns=X.columns)\n        return cols_representation\n    \ndef process_data(data: pd.DataFrame):\n    data['ord_5_1'] = data['ord_5'].apply(lambda x: x[0])\n    data['ord_5_2'] = data['ord_5'].apply(lambda x: x[1])\n\n    mapper_ord_1 = {'Novice': 1, \n                'Contributor': 2,\n                'Expert': 3, \n                'Master': 4, \n                'Grandmaster': 5}\n\n    mapper_ord_2 = {'Freezing': 1, \n                    'Cold': 2, \n                    'Warm': 3, \n                    'Hot': 4,\n                    'Boiling Hot': 5, \n                    'Lava Hot': 6}\n\n    mapper_ord_3 = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, \n                    'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15}\n\n    mapper_ord_4 = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, \n                    'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15,\n                    'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, \n                    'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n    \n    for col, mapper in zip(['ord_1', 'ord_2', 'ord_3', 'ord_4'], [mapper_ord_1, mapper_ord_2, mapper_ord_3, mapper_ord_4]):\n        data[col] = data[col].replace(mapper)\n        \n    ord_5 = sorted(list(set(data['ord_5'].values)))\n    ord_5 = dict(zip(ord_5, range(len(ord_5))))\n    data.loc[:, 'ord_5'] = data['ord_5'].apply(lambda x: ord_5[x]).astype(float)\n    \n    data['bin_3'] = data['bin_3'].apply(lambda x: 1 if x == 'T' else 0)\n    data['bin_4'] = data['bin_4'].apply(lambda x: 1 if x == 'Y' else 0)\n    \n    def date_cyc_enc(df, col, max_vals):\n        df[col + '_sin'] = np.sin(2 * np.pi * df[col]/max_vals)\n        df[col + '_cos'] = np.cos(2 * np.pi * df[col]/max_vals)\n        return df\n\n    data = date_cyc_enc(data, 'day', 7)\n    data = date_cyc_enc(data, 'month', 12)\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_le(X, X_test, cols):\n    X_tr = pd.DataFrame()\n    X_te = pd.DataFrame()\n    new_cols = []\n    for c in cols:\n        c_name = c + '_le'\n        new_cols.append(c_name)\n        le = LabelEncoder()\n        le.fit(list(X[c].astype(str).values) + list(X_test[c].astype(str).values))\n        X_tr[c_name] = le.transform(list(X[c].astype(str).values))\n        X_te[c_name] = le.transform(list(X_test[c].astype(str).values))\n    return X_tr, X_te, new_cols\n\ndef do_ohe(X, X_test, cols):\n    X_tr = pd.DataFrame()\n    X_te = pd.DataFrame()\n    X_tr = pd.get_dummies(X[cols])\n    X_te = pd.get_dummies(X_test[cols])\n    return X_tr, X_te\n\ndef do_hash(X, X_test, cols, preffix=None, n_feats=None):\n    if preffix is None:\n        raise ValueError('preffix should be set.')\n    if n_feats is None:\n        raise ValueError('n_feats should be set.')\n    X_tr = pd.DataFrame()\n    X_te = pd.DataFrame()\n    new_cols = []\n    \n    for c in cols:\n        c_name = c+'_hash'\n        new_cols.append(c_name)\n        size = X[c].nunique()\n        X_tr[c_name] = X[c].apply( lambda x: hash(str(x)) % size )\n        X_te[c_name] = X_test[c].apply( lambda x: hash(str(x)) % size )\n    \n    return X_tr, X_te, new_cols\n\ndef do_bin(X, X_test, cols):\n    X_tr = pd.DataFrame()\n    X_te = pd.DataFrame()\n    be = category_encoders.BinaryEncoder(cols=cols).fit(X[cols])\n    X_tr = be.transform(X[cols])\n    X_te = be.transform(X_test[cols])\n    new_cols = list(X_tr.columns)\n    return X_tr, X_te, new_cols\n\ndef do_freq(X, X_test, cols):\n    X_tr = pd.DataFrame()\n    X_te = pd.DataFrame()\n    new_cols = []\n    for c in cols:\n        c_name = c+'_freq'\n        new_cols.append(c_name)\n        tmp = pd.concat([X[[c]], X_test[[c]]])\n        enc = tmp[c].value_counts().to_dict()   \n        X_tr[c_name] = X_tr[c].map(enc)\n        X_te[c_name]  = X_te[c].map(enc)\n    return X_tr, X_te, new_cols","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '/kaggle/input/cat-in-the-dat/'\ntrain = pd.read_csv(path + 'train.csv')\ntest = pd.read_csv(path + 'test.csv')\nsub = pd.read_csv(path+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cat_feats = [c for c in train.columns if c not in ['id','target']]\n# train = process_data(train)\n# test = process_data(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['id','target'],1)\ny = train.target\nX_test = test.drop(['id'],1)\ntest = test[['id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lc_nom = [f'nom_{i}'for i in range(0,5)]\n# hc_nom = [f'nom_{i}'for i in range(5,10)]\n# lc_ord = [f'ord_{i}'for i in range(0,3)]\n# hc_ord = [f'ord_{i}'for i in range(3,6)]\n\n# # BINARY ENCODER for HIGH cardinality ORDINAL columns\n# for_bin = hc_ord\n# X_bin, X_test_bin, bin_cols = do_bin(X, X_test, for_bin)\n\n# # OHE for LOW cardinality NOMINAL and ORDINAL columns\n# for_ohe = lc_nom\n# X_ohe, X_test_ohe = do_ohe(X, X_test, for_ohe)\n\n# # HASHING for HIGH cardinality NOMINAL and ORDINAL columns\n# for_hash = hc_nom\n# n_feats = X[for_hash].nunique().sum()\n# X_hash, X_test_hash, hash_cols = do_hash(X,X_test,for_hash,'_nom', n_feats=n_feats)\n\n# # LABEL ENCODER for LOW cardinality ORDINAL columns\n# for_le = lc_ord + ['ord_5_1', 'ord_5_2']\n# X_le, X_test_le, le_cols = do_le(X, X_test, for_le)\n\n# # # FREQUENCY ENCODER\n# # for_freq = []\n# # X_freq, X_test_freq, freq_cols = do_freq(X, X_test, for_freq)\n\n# # del X_freq, X_test_freq\n# # gc.collect()\n\n# X.drop(\n#     list(\n#         for_bin+\n#         for_le+\n#         for_ohe+\n#         for_hash\n#         )\n#     ,1, inplace=True)\n# X_test.drop(\n#    list(\n#        for_bin+\n#         for_le+\n#         for_ohe+\n#         for_hash)\n#     ,1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X = pd.concat([X, \n#                X_bin,\n#                X_le,\n#                X_ohe,\n#                X_hash,\n#               ],1)\n# del  X_bin, X_le, X_ohe, X_hash\n# gc.collect()\n\n# X_test = pd.concat([X_test, \n#                     X_test_bin,\n#                     X_test_le,\n#                     X_test_ohe,\n#                     X_test_hash,\n#                    ],1)\n# del  X_test_bin, X_test_le, X_test_ohe, X_test_hash\n# gc.collect()\n# print(X.shape,X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow as tf\nimport keras.backend as K\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Dropout, BatchNormalization, Activation, Concatenate, Embedding, Flatten\nfrom keras.optimizers import Adam, Nadam\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\nfrom  keras.regularizers import l2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dae(X):\n    inp = Input((X.shape[1],))\n    x = Dense(512, activation='relu')(inp)\n    x = Dense(256, activation='relu')(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(.2)(x)\n    y = Dense(X.shape[1], activation='linear')(x)\n    \n    model = Model(inputs=inp, outputs=y)\n    model.compile(optimizer='adam',\n                  loss='mse')\n    return model\n\ndef add_noise(arr, p):\n    n, m = arr.shape\n    idx_arr = range(n)\n    swap_n = round(n*p)\n    for i in range(m):\n        col_vals = np.random.permutation(arr[:, i])\n        swap_idx = np.random.choice(idx_arr, size= swap_n) \n        arr[swap_idx, i] = np.random.choice(col_vals, size = swap_n) \n    return arr\n\ndef data_gen(X, swap_rate, batch_size):\n    idxs = np.arange(X.shape[0])\n    while True:\n        np.random.shuffle(idxs)\n        X_orig = X[idxs[:batch_size]] \n        X_noisy = add_noise(X_orig, swap_rate)\n        yield X_noisy, X_orig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nX, X_test, _ = do_le(X, X_test, list(X.columns))\nmm = MinMaxScaler()\nX = mm.fit_transform(X)\nX_test = mm.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 2**11\nepochs = 1\ngen = data_gen(X, .15, batch_size)\ndae = get_dae(X)\ndae.fit_generator(generator=gen,\n                 steps_per_epoch=X.shape[0]// batch_size,\n                 epochs=epochs,\n                 use_multiprocessing=True,\n                 verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dae.trainable = False\ndae.compile(optimizer='adam',\n                  loss='mse')\ndae.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def auc(y_true, y_pred):\n    def fallback_auc(y_true, y_pred):\n        try:\n            return roc_auc_score(y_true, y_pred)\n        except:\n            return 0.5\n    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)\n\ndef get_nn(X, dae):\n    x1 = dae.layers[1].output\n    x2 = dae.layers[2].output\n    x3 = dae.layers[3].output\n    x = Concatenate()([x1, x2, x3])\n    \n    x = Dense(500, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(200, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(100, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    \n    nunique = len(np.unique(X))\n    emb_size = int(min(50, nunique//2))\n    max_len = X.shape[1]\n    inp_z = Input(shape=(max_len,))\n    z = Embedding(nunique+1, emb_size,input_length=max_len)(inp_z)\n    z = Flatten()(z)\n    z = Dropout(0.2)(z)\n    z = Dense(2**6, activation = 'relu')(z)\n    z = Dropout(0.2)(z)\n    z = Dense(2**6, activation = 'relu')(z)\n    z = Dropout(0.2)(z)\n    \n    conc = Concatenate()([x, z])\n    y = Dense(1, activation='sigmoid')(conc)\n    \n    model = Model(inputs=[dae.input,inp_z], outputs=y)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                 metrics=[auc])\n    \n    return model\n\ndef get_callbacks():\n    es = EarlyStopping(monitor='val_auc',\n                      min_delta=0.001,\n                      patience=2,\n                      verbose=1,\n                      mode='max',\n                      baseline=None,\n                      restore_best_weights=True)\n    \n    rlr = ReduceLROnPlateau(monitor='val_auc',\n                           factor=0.5,\n                           patience=3,\n                           min_lr=1e-6,\n                           mode='max',\n                           verbose=1)\n    return [es, rlr]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DoubleValidationEncoderNumerical:\n    def __init__(self, cols, encoder, folds):\n        self.cols = cols\n        self.encoder = encoder\n        self.encoders_dict = {}\n        self.folds = folds\n\n    def fit_transform(self, X: pd.DataFrame, y: np.array) -> pd.DataFrame:\n        X = X.reset_index(drop=True)\n        y = y.reset_index(drop=True)\n        for n_fold, (train_idx, val_idx) in enumerate(self.folds.split(X, y)):\n            X_train, X_val = X.loc[train_idx].reset_index(drop=True), X.loc[val_idx].reset_index(drop=True)\n            y_train, y_val = y[train_idx], y[val_idx]\n            _ = self.encoder.fit_transform(X_train[self.cols], y_train)\n            \n            val_t = self.encoder.transform(X_val)\n            val_t = val_t.fillna(np.mean(y_train))\n            if n_fold == 0:\n                cols_representation = np.zeros((X.shape[0], val_t.shape[1]))\n            \n            self.encoders_dict[n_fold] = self.encoder\n            cols_representation[val_idx, :] += val_t.values\n        cols_representation = pd.DataFrame(cols_representation, columns=X.columns)\n        return cols_representation\n\n    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n        X = X.reset_index(drop=True)\n        cols_representation = None\n        for encoder in self.encoders_dict.values():\n            test_tr = encoder.transform(X)\n\n            if cols_representation is None:\n                cols_representation = np.zeros(test_tr.shape)\n            cols_representation = cols_representation + test_tr / self.folds.n_splits\n        cols_representation = pd.DataFrame(cols_representation, columns=X.columns)\n        return cols_representation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 2*11\nEPOCHS = 10\nN_SPLITS = 5\nSEED = 555\n\npreds = np.zeros(X_test.shape[0])\noof = np.zeros(X.shape[0])\n\nskf = StratifiedKFold(n_splits=N_SPLITS, random_state=SEED, shuffle=True)\ncat_feats = list(train.columns)\ncat_feats.remove('id')\ncat_feats.remove('target')\n\nfor i, (tr, val) in enumerate(skf.split(X,y)):\n    print(f'Fold #{i}')\n    X_tr, X_val = X[tr], X[val]\n    y_tr, y_val = y[tr], y[val]\n    \n    model = get_nn(X,dae)\n    model.fit(x=list([X_tr,X_tr]), y=y_tr,\n                validation_data=(X_val, y_val),\n                batch_size=BATCH_SIZE,\n                epochs=EPOCHS,\n                verbose=1,\n                callbacks = get_callbacks(),\n                shuffle=True)\n\n    train_pred = model.predict(X_tr)[:,0] \n    oof_pred = model.predict(X_val)[:,0]\n    pred = model.predict(X_test)[:, 0]\n    \n    oof[val] = oof_pred.ravel()\n    preds += pred\n    \n    print('-'*40)\n    print('Fold {}:\\t train {:.5f} val {:.5f}'.format(i, roc_auc_score(y_val, oof_pred),roc_auc_score(y_tr, train_pred)))\n    print('-'*40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['pred'] = preds / N_SPLITS\nsub['target'] = pd.merge(sub, test, on='id')['pred']\nsub.to_csv('nn.csv')\nsub.tail()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}